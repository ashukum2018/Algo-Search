Given an integer n, return an array ans of length n + 1 such that for each i (0 <= i <= n), ans[i] is the number of 1's in the binary representation of i. <br><h4>Example 1:</h4> <br><h4>Input:</h4> n = 2 <br><h4>Output:</h4> [0,1,1] <br><h4>Explanation:</h4> 0 --> 0 1 --> 1 2 --> 10 <br><h4>Example 2:</h4> <br><h4>Input:</h4> n = 5 <br><h4>Output:</h4> [0,1,1,2,1,2] <br><h4>Explanation:</h4> 0 --> 0 1 --> 1 2 --> 10 3 --> 11 4 --> 100 5 --> 101 <br><h4>Constraints:</h4> 0 <= n <= 105 Follow up:</h4> It is very easy to come up with a solution with a runtime of O(n log n). Can you do it in linear time O(n) and possibly in a single pass? Can you do it without using any built-in function (i.e., like __builtin_popcount in C++)?